{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3bf85f9a-bc9d-4169-b935-e08b5fc1b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegressionSGD:\n",
    "\n",
    "    def __init__(self, learning_rate = 0.01, batch_size = 10, max_iterations = 1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iterations = max_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def error_function(self, y, t):\n",
    "        return -np.mean(t * np.log(y + 1e-9) + (1 - t) * np.log(1 - y + 1e-9))\n",
    "\n",
    "    def train(self, X, t):\n",
    "        N, d = X.shape\n",
    "        self.weights = np.random.randn(d) * 0.01\n",
    "\n",
    "        for j in range(self.max_iterations):\n",
    "            indices = np.random.permutation(N)\n",
    "            X_random, t_random = X[indices], t[indices]\n",
    "\n",
    "            for i in range(0, N, self.batch_size):\n",
    "                X_batch = X_random[i:i + self.batch_size]\n",
    "                t_batch = t_random[i:i + self.batch_size]\n",
    "\n",
    "                y_batch = self.sigmoid(X_batch @ self.weights).reshape(-1)\n",
    "                t_batch = t_batch.reshape(-1)\n",
    "\n",
    "                gradient = X_batch.T @ (y_batch - t_batch) / len(t_batch)\n",
    "\n",
    "                self.weights -= self.learning_rate * gradient\n",
    "\n",
    "            y_pred_train = self.sigmoid(X @ self.weights)\n",
    "            y_pred_train = y_pred_train[: len(t)]  \n",
    "            \n",
    "            loss = self.error_function(y_pred_train, t)\n",
    "\n",
    "    def predict_probability(self, X):\n",
    "        return self.sigmoid(X @ self.weights)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.predict_probability(X) >= 0.5).astype(int)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9b926e8-5c11-4820-be2a-1e9e9738e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "24ab7f38-b343-4d1c-8c67-9fe4c8b6c21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 180, 1: 303}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size = 0.5, random_state = 42, stratify = y_temp)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "unique, counts = np.unique(np.concatenate((y_train, y_val)), return_counts=True)\n",
    "class_size = dict(zip(unique, counts))\n",
    "class_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0889a5f6-6b5c-4038-96c6-49fafc8a04d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9767441860465116, 0.9642857142857143, 1.0, 0.9818181818181818)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegressionSGD(learning_rate = 0.1, batch_size = 20, max_iterations = 1000)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e66f6a-9c3c-47da-84ba-9e00d4aab3fe",
   "metadata": {},
   "source": [
    "The model correctly classified 97.7% of the test data.\n",
    "96.4% of the time, the model correctly classified the benign cases as benign. Sometimes it misclassified the benign cases as bad.\n",
    "There were zero false negatives, the model successfully identified all tumors.\n",
    "The F1 score was 98.18% which means that the model was highly reliable for classification and it performed very well in precision and recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
